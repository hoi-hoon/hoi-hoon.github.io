---
title:  "[공부 노트] #5"
excerpt: "1월 3주차 공부 노트"

categories:
  - Study
tags: Study Note
last_modified_at: 2021-01-24T12:00:00
---
nlp 공모전에 참가 신청을 일단 해놓고, 관련 공부를 하기로 했다. nlp를 아예 처음으로 접하기 때문에 기초 수준의 튜토리얼을 따라가며 공부하기로 했다. 우선 앞부분의 챕터에서는 데이터의 전처리에 대해서 배우는데, 토큰화(tokenization), 정제(cleaning), 정규화(normalization)에 대해서 공부했다.

## Q1. 토큰화(tokenization)
주어진 코퍼스(말뭉치, 대량의 텍스트 데이터를 의미함)를 토큰(token)이라는 단위로 나누는 작업이다. 토큰의 단위는 상황에 따라 다르다.  
토큰화 작업은 단순히 공백 기준으로 문자를 잘라내는 작업이 아니다.

- 특수 문자를 단순 제외하면 안된다 : 마침표(.)의 경우 문장의 경계를 나타내줄 수 있고, 'Ph.D' 처럼 단어 내에 마침표가 존재할 수 있다.
- 줄임말 혹은 단어 내 띄어쓰기 :  rock 'n' roll 이라는 단어 처럼 중간에 띄어쓰기가 있는 경우에도 해당 단어를 하나로 인식할 수 있어야한다.

## Q2. 형태소(morpheme)
한국어가 영어와 달리 띄어쓰기로 토큰화하기 힘든 이유는, 영어와 달리 한국어가 '교착어'라는 점이다. 교착어란 조사, 어미를 붙여 말을 만드는 언어이다. 따라서 한국어는 어절이 독립적인 단어로 구성되어 있지 않은 경우가 많아서, 이것을 전부 분리해줘야 한다는 것이다. 그래서 한국어를 토큰화하기 위해서는 형태소의 개념을 이해해야하는데, 형태소란 뜻을 가지는 가장 작은 말의 단위이다. 형태소는 다음과 같이 나눌 수 있다.  


**자립성 기준**
- 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소. 그 자체로 단어가 된다. 체언(명사, 대명사, 수사), 수식언(관형사, 부사), 감탄사 등이 있다.
- 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소. 접사, 어미, 조사, 어간를 말한다.

**의미와 기능 기준**
- 실질 형태소 : 실제 의미를 갖는 형태소. 자립 형태소는 모두 실질형태소이고, 의존 형태소 중 용언(동사와 형용사)의 어간만이 유일하게 실질형태소이다.
- 형식 형태소 : 실질 형태소에 붙어서 말 사이의 관계를 표시하는 형태소로, 접사, 어미,조사를 말한다.

## Q3. 정규화(normalization)
정규화는 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어주는 것이다.

- 표제어 추출(Lemmatization) : 단어들이 다른 형태를 가지더라도, 그 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지 판단. 'are', 'is', 'am'은 모두 다르지만, 'be'에 뿌리를 두고 있다.
- 어간 추출(Stemming) : 어간 추출은 형태학적 분석을 단순화한 버전으로, 섬세한 작업이 아니기 때문에 어간 추출 후에 나오는 결과 단어는 사전에 존재하지 않는 단어일 수도 있다. 어간 추출이 대체로 표제어 추출보다 빠르고, 특히 포터 어간추출 알고리즘은 영어를 기준으로 상당히 높은 정확도를 보여준다고 한다.
  - 활용 : 어간이 어미를 가지는 것이다.
    - 규칙 활용 : 어간과 어미가 합쳐질 때, 어간의 모습이 일정(잡 + 다)
    - 불규칙 활용 : 오르 + 아 -> 올라 / 이르 + 어 -> 이르러

## Q4. 불용어(Stopword)
불용어는 분석에 큰 의미가 없는 단어를 말한다. 예를들어 I, my, me, over, 조사, 접미사 같은 단어들은 문장에서는 자주 등장하지만 실제 의미 분석을 하는데는 거의 기여하는 바가 없다 - 라고 튜토리얼에 적혀있는데, 사실 잘 이해가 되지 않는 부분이다. 문장을 분석하는데 있어서 조사나 접미사도 매우 중요한 부분이라고 생각하기 때문이다. 어떤 문장에서 빼도 되는 단어나 부분은 있을 수 있겠지만, 그것은 그 문맥에서만 적용되는 것이지 일반적으로 적용할 수 있는 것인가에 대한 의문점이 들었다. 그래서 불용어라는 개념에 대해서 더 찾아보았으나, 대부분 튜토리얼 수준에서 정의를 내린 자료들 뿐이었다. 계속 공부하면서 의문점을 풀어낼 수 있기를 바라며, 현재 수준에서는 

## Q5. 정규표현식

| 특수 문자	| 설명 |
| --- | ---|
|.	| 한 개의 임의의 문자 (줄바꿈 문자인 \n는 제외) |
|?	| 앞의 문자가 0개 또는 1개 |
|*	| 앞의 문자가 0개 이상 |
|+	| 앞의 문자가 최소 1개 이상 |
|^	| 뒤의 문자로 문자열이 시작 |
|$	| 앞의 문자로 문자열이 끝 |
|{숫자}	| 숫자만큼 반복 | 

|문자 규칙 |	설명 |
| --- | --- |
| \\d	| 모든 숫자를 의미. [0-9]와 동일 |
| \\D	| 숫자를 제외한 모든 문자를 의미. [^0-9]와 동일 |
| \\s	| 공백을 의미 |
| \\S	| 공백을 제외한 문자를 의미 |
| \\w	| 문자 또는 숫자를 의미. [a-zA-Z0-9]와 동일 |
| \\W	| 문자 또는 숫자가 아닌 문자를 의미. [^a-zA-Z0-9]와 동일 |

## Q6. 한국어 전처리 패키지
1. PyKoSpacing : 띄어쓰기가 되어있지 않은 문장을 띄어쓰기를 한 문장으로 변환해주는 패키지
2. Py-Hanspell : 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지. 띄어쓰기 또한 보정되는데, PyKoSpacing와는 다른 결과를 낼 때가 있다.
3. SOYNLP : 품사 태깅, 단어 토큰화 등을 지원하는 단어 토크나이저. 비지도 학습으로 데이터에 자주 등장하는 단어들을 단어로 분석한다.

SOYNLP는 학습 과정을 거쳐야하는 토크나이저인데, 전체 코퍼스로부터 응집 확률과 브랜칭 엔트로피를 이용해서 단어 점수표를 만든다.
- 응집 확률(cohesion probability) : 내부 문자열이 얼마나 응집해서 자주 등장하는지 판단하는 척도.
- 브랜칭 엔트로피(branching entropy) : 주어진 문자열에서 다음 문자가 등장할 수 있는지를 판단하는 척도


```python
#응집 확률
word_score_table["반포한"].cohesion_forward
0.08838002913645132
word_score_table["반포한강"].cohesion_forward
0.19841268168224552
word_score_table["반포한강공"].cohesion_forward
0.2972877884078849
word_score_table["반포한강공원"].cohesion_forward
0.37891487632839754
word_score_table["반포한강공원에"].cohesion_forward
0.33492963377557666

#브랜칭 엔트로피
word_score_table["디스"].right_branching_entropy
1.6371694761537934
word_score_table["디스플"].right_branching_entropy
-0.0
word_score_table["디스플레"].right_branching_entropy
-0.0
word_score_table["디스플레이"].right_branching_entropy
3.1400392861792916
```

참고문헌
> https://wikidocs.net/21698